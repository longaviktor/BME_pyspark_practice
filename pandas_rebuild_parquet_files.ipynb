{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prqt_loc = '../../../../datasets/ess/parquet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Output:\n",
      "\n",
      "ESS1_180115.parquet\n",
      "ESS2_180115.parquet\n",
      "ESS3_180115.parquet\n",
      "ESS4_190213.parquet\n",
      "ESS5_180115.parquet\n",
      "ESS6_180115.parquet\n",
      "ESS7_180115.parquet\n",
      "ESS8_190213.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = subprocess.Popen(f'ls {prqt_loc}', shell=True, stdout=subprocess.PIPE)\n",
    "ret = p.communicate()\n",
    "print('Exit code: {}\\nOutput:\\n\\n{}'.format(p.returncode, ret[0].decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquets = [ pqt for pqt in ret[0].decode('utf-8').split('\\n') if pqt.find('.parquet') > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes = pd.DataFrame()\n",
    "for parquet in parquets:\n",
    "    df = pd.read_parquet(f\"{prqt_loc}{parquet}\")\n",
    "    dtype_dict = df.dtypes.to_dict()\n",
    "    for key in dtype_dict:\n",
    "        df_dtypes.loc[parquet,key] = dtype_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_schema_new = {}\n",
    "for col in df_dtypes.columns:\n",
    "    if df_dtypes[col].isna().sum() > 0:\n",
    "        if df_dtypes[col].value_counts().index[0] == np.dtype('O'):\n",
    "            ess_schema_new[col] = np.dtype('O')\n",
    "        else:\n",
    "            ess_schema_new[col] = np.dtype('float64')\n",
    "    else:\n",
    "        ess_schema_new[col] = df_dtypes[col].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_naint = []\n",
    "for col in ess_schema_new.keys():\n",
    "    if ess_schema_new[col] == np.dtype('int64'):\n",
    "        if df[col].isna().sum() > 0:\n",
    "            cols_naint.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_naint:\n",
    "    ess_schema_new[col] = np.dtype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESS1_180115.parquet\n",
      "##repair schema ctzship\n",
      "##repair schema ctzshipa\n",
      "##repair schema cntbrth\n",
      "##repair schema cntbrtha\n",
      "ESS2_180115.parquet\n",
      "##repair schema fbrncnt\n",
      "##repair schema mbrncnt\n",
      "ESS3_180115.parquet\n",
      "ESS4_190213.parquet\n",
      "##repair schema ctzshipb\n",
      "##repair schema cntbrthb\n",
      "##repair schema fbrncnta\n",
      "##repair schema mbrncnta\n",
      "ESS5_180115.parquet\n",
      "ESS6_180115.parquet\n",
      "ESS7_180115.parquet\n",
      "ESS8_190213.parquet\n"
     ]
    }
   ],
   "source": [
    "for parquet in parquets:\n",
    "    #test and repair ess_schema_new\n",
    "    print(parquet)\n",
    "    df = pd.read_parquet(f\"{prqt_loc}{parquet}\")\n",
    "    diff_col = list( set(ess_schema_new.keys()) - set(df.columns) )\n",
    "    df2 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame(columns = [col for col in diff_col])\n",
    "    df2 = pd.concat([df,df2],sort=False)\n",
    "    for col in list(ess_schema_new.keys()):\n",
    "        try:\n",
    "            df2[col] = df2[col].astype( ess_schema_new[col] , copy=False)\n",
    "        except:\n",
    "            value_dict = {}\n",
    "            for value in df2[col].value_counts().index:\n",
    "                if type(value) in value_dict.keys():\n",
    "                    value_dict[type(value)] += 1\n",
    "                else:\n",
    "                    value_dict[type(value)] = 1\n",
    "            if sorted( list( value_dict.keys()  ), key= lambda x: -value_dict.get(x)  )[0] == str:\n",
    "                ess_schema_new[col] = np.dtype('O')\n",
    "            else:\n",
    "                ess_schema_new[col] = np.dtype('float64')\n",
    "            print('##repair schema',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESS1_180115.parquet\n",
      "ESS2_180115.parquet\n",
      "ESS3_180115.parquet\n",
      "ESS4_190213.parquet\n",
      "ESS5_180115.parquet\n",
      "ESS6_180115.parquet\n",
      "ESS7_180115.parquet\n",
      "ESS8_190213.parquet\n"
     ]
    }
   ],
   "source": [
    "for parquet in parquets:\n",
    "    #Rebuild parquets\n",
    "    print(parquet)\n",
    "    df = pd.read_parquet(f\"{prqt_loc}{parquet}\")\n",
    "    diff_col = list( set(ess_schema_new.keys()) - set(df.columns) )\n",
    "    df2 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame(columns = [col for col in diff_col])\n",
    "    df2 = pd.concat([df,df2],sort=False)\n",
    "    for col in list(ess_schema_new.keys()):\n",
    "        df2[col] = df2[col].astype( ess_schema_new[col] , copy=False)\n",
    "    #pandas to arrwo type differences\n",
    "    pta_td = {np.dtype('float64'):pa.float64(),\n",
    "                      np.dtype('int64'):pa.int64(),\n",
    "                      np.dtype('datetime64[ns]'):pa.timestamp('ns'),\n",
    "                      np.dtype('O'):pa.string()}\n",
    "    schema = pa.schema([ pa.field(key, pta_td[ ess_schema_new[key] ], nullable=True) for key in ess_schema_new.keys() ])\n",
    "    table = pa.Table.from_pandas(df2[list(ess_schema_new.keys())], schema=schema,preserve_index=False)\n",
    "    pq.ParquetWriter(f\"{prqt_loc}ns_{parquet}\", table.schema).write_table(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3int]",
   "language": "python",
   "name": "conda-env-py3int-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
